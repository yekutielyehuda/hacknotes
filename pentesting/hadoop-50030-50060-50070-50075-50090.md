# Hadoop - 50030,50060,50070,50075,50090

## **Basic Information** <a id="basic-information"></a>

##  <a id="basic-information"></a>

Apache Hadoop is an open source platform for storing and processing massive datasets in distributed computing clusters. The Hadoop Distributed File System \(HDFS\) handles storage, while MapReduce and other applications \(such as Apache Storm, Flink, and Spark\) handle the processing.

The Nmap scripts described in the table below can be used to query MapReduce and HDFS services \(including details of the default ports\). 

| **Script name** | **Port** | **Purpose** |
| :--- | :--- | :--- |
| hadoop-jobtracker-info | 50030 | Retrieve information from MapReduce job and task tracker services |
| hadoop-tasktracker-info | 50060 | â€‹ |
| hadoop-namenode-info | 50070 | Retrieve info from HDFS name node |
| hadoop-datanode-info | 50075 | Retrieve info from HDFS data node |
| hadoop-secondary-namenode-info | 50090 | Retrieve info from HDFS secondary name node |

Clients for HDFS in Python and Go are available online. By default, Hadoop runs without authentication. Kerberos can be configured for HDFS, YARN, and MapReduce services.

